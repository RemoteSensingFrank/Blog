---
title: kmeans与dbscan
date: 2017-04-29 16:57:50
tags: 数学
categories: 数学
---
最近学习Ｒ语言，感觉Ｒ语言还不错，总的来说算是学的颇有心得了，所以想通过一个模拟数据进行分类实验试试，但是分类的结果确实是很有意思，所以在这里稍稍记录了一下，以后遇到同样的问题也可以作为参考．  
首先我做了两个正态分布的数据如图：
![raw image](https://lh3.googleusercontent.com/-BACSYwa4gsM/WQReo0KC5PI/AAAAAAAACLU/DrAHRXT4DXQ6IrTP6LNZPgNrZtuRFvKiQCLcB/s0/raw.png "raw.png")
从图上可以看出，明显存在两类分别为红色和绿色，这两个类是模拟的正态分布的，一开始以为很简单可以用ｋ均值分类的算法进行分类，然而实际上通过ｋ均值算法进行分类的结果为：
![kmeans](https://lh3.googleusercontent.com/-d2GnfVvDdz8/WQRhi8rnGaI/AAAAAAAACLk/AbHQC80WKi8b7E0W_S9HczTCX-hJyvp7ACLcB/s0/kmeans.png "kmeans.png")
其中蓝色和绿色分别为两个聚类中心，从聚类的结果来看，聚类结果并不好，从聚类结果来看，原始数据中的绿色部分可以被分出来，然而对于红色部分分类的结果不太好，稍后我们将仔细对比分析两种分类方法的差异以及导致分类结果产生的差异．下面是dbscan的分类结果：
![dbscan](https://lh3.googleusercontent.com/-sDM16_GH33w/WQRkdYTOHYI/AAAAAAAACL4/7svTJTUk0JsrtE3TwSixh4QIhuW3wrIIwCLcB/s0/dbscan.png "dbscan.png")
对比原始数据和dbscan的结果我们可以看出，dbscan的结果能够很好的将数据分为两类，且根据数据的密度进行了分类，与kmeans的分类结果相比采用dbscan的分类结果能够更好的将两个正态分布的样本进行区分，得到更好的分类效果，而dbscan也存在这一定的局限性，通过dbscan进行分类无法对所有数据进行分类，具有较大的漏分误差，下面分析两种分类方法的具体实现：
><b>kmeans:  
kmeans方法首先给定分类数，则该方法随机选取了聚类中心，然后根据聚类中心对所有点进行聚类，然后对于聚类结果继续求取聚类中心，如此迭代直到聚类中心不发生改变．

从以上描述可以看出，通过kmeans算法进行分类主要是通过样本到聚类中心的距离进行分类，仅仅考虑了距离并没有考虑到样本的分布情况，因此对于模拟数据，由于两个样本的离散度存在差异，因此存在较大的误差．
><b>dbscan:  
dbscan算法首先假设所有数据都是单独的一类，然后通过样本与样本之间的距离进行聚类，样本之间距离小于某一个阈值则进行聚类，而样本之间的距离大于阈值则不聚类，此类算法需要有两个参数分别为：距离阈值以及每一类的最少的点的数目，最小点的数目表示当聚类过程中某一类的样本数目小于给定的阈值则认为是误差数据．

与kmeans算法相比dbscan算法不是根据给定类的数目进行聚类，而是自动的进行聚类并获取类的数目，实际上分类结果有距离阈值和类内最小点的数目共同确定，因此参数的设定对于聚类结果有较大的影响．采用dbscan方法进行聚类能够根据密度进行聚类，然而针对密度不同的类别依然存在较大的误差，同时此方法还存在这具有较多漏分数据的情况，但是针对两个密集的聚集数据采用此方法有比较好的分类效果．
